{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "805d25c7",
   "metadata": {},
   "source": [
    "\n",
    "# Polynomial Regression Assignment\n",
    "\n",
    "---\n",
    "\n",
    "In this assignment, you will explore **polynomial regression**, an extension of linear regression models that captures non-linear relationships between variables by adding powers of the original features.\n",
    "\n",
    "## Objective\n",
    "By the end of this assignment, you will:\n",
    "- Understand the concept of polynomial regression and how it differs from linear regression.\n",
    "- Learn how to implement polynomial regression in Python.\n",
    "- Compare the performance of linear and polynomial models on a dataset to observe the impact of model complexity.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5313a0d574f3d266",
   "metadata": {},
   "source": [
    "## About Dataset\n",
    "### Manufacturing Data Report\n",
    "This report presents an analysis of a manufacturing dataset, which simulates real-world data collected from a manufacturing process. The dataset is designed to explore the relationships between various process parameters and product quality. It contains both feature variables that represent process conditions and a target variable that represents the quality rating of the manufactured items.\n",
    "\n",
    "**This dataset is clean and does not require any preprocessing steps.**\n",
    "\n",
    "### Features\n",
    "Temperature (°C): This column represents the temperature during the manufacturing process, measured in degrees Celsius. Temperature plays a critical role in many manufacturing processes, influencing material properties and product quality.\n",
    "\n",
    "Pressure (kPa): The pressure applied during the manufacturing process, measured in kilopascals (kPa). Pressure can affect the material transformation and the overall outcome of the manufacturing process.\n",
    "\n",
    "Temperature x Pressure: This feature is an interaction term between temperature and pressure, which captures the combined effect of these two process parameters.\n",
    "\n",
    "Material Fusion Metric: A derived metric calculated as the sum of the square of temperature and the cube of pressure. It represents a material fusion-related measurement during the manufacturing process.\n",
    "\n",
    "Material Transformation Metric: Another derived metric calculated as the cube of temperature minus the square of pressure. It provides insight into material transformation dynamics.\n",
    "\n",
    "Quality Rating: The target variable, 'Quality Rating,' represents the overall quality rating of the produced items. Quality is a crucial aspect of manufacturing, and this rating serves as a measure of the final product's quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e42aa4d7d08fa51",
   "metadata": {},
   "source": [
    "\n",
    "## Assignment Instruction Overview\n",
    "\n",
    "#### 0. Preliminary steps\n",
    "Set up the environment by importing necessary libraries (such as numpy, pandas, and matplotlib) and ensure the dataset is accessible for loading. This step ensures you have the required tools to work with data and perform polynomial regression.\n",
    "\n",
    "#### 1. Loading and Visualizing the Data\n",
    "Load the dataset into a DataFrame and plot it to observe the relationship between features and the target variable. This initial exploration helps determine if the data exhibits a non-linear pattern that may benefit from polynomial regression.\n",
    "\n",
    "#### 2. Prepare the dataset\n",
    "Preprocess the data by selecting the feature(s) and target variable, handling any missing values, and potentially scaling the data if needed. Preparing the dataset is key for obtaining meaningful and consistent results from the model.\n",
    "\n",
    "#### 3. Fitting Polynomial Regression Models\n",
    "Transform the features into polynomial terms and fit a polynomial regression model to capture non-linear relationships. Begin with a lower degree and increase it as needed to balance model complexity and accuracy.\n",
    "\n",
    "#### 4. Visual Comparison\n",
    "Compare the fitted polynomial regression model with a simple linear regression model visually. Plotting both models against the data helps illustrate how polynomial regression captures patterns that linear regression cannot.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be55ff5a02b515eb",
   "metadata": {},
   "source": [
    "### 0. Preliminary steps\n",
    "Install and import any libraries you may need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24478160a35cd1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T13:29:30.694465Z",
     "start_time": "2024-11-13T13:29:30.691030Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Install core libraries for polynomial regression\n",
    "# !pip install --quiet scikit-learn\n",
    "# !pip install --quiet matplotlib\n",
    "# !pip install --quiet pandas\n",
    "# !pip install --quiet numpy\n",
    "# !pip install --quiet seaborn\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e51574a8e4ecbbec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T13:29:30.722275Z",
     "start_time": "2024-11-13T13:29:30.718645Z"
    }
   },
   "outputs": [],
   "source": [
    "# Core library imports for polynomial regression on the manufacturing dataset.\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46204102138e0408",
   "metadata": {},
   "source": [
    "### 1. Loading and visualizing the data\n",
    "In this step, we will load the dataset, inspect its structure, and create a visualization to understand the relationship between the feature(s) and the target variable.\n",
    "\n",
    "1. **Load the Dataset**: Use `pandas.read_csv()` or another appropriate method to load the dataset into a DataFrame.\n",
    "\n",
    "2. **Inspect the Data**: Print out the first few rows of the data using `.head()` to get a sense of its structure and identify any key columns.\n",
    "\n",
    "3. **Visualize the Data**: Useful libraries for visualization include `matplotlib` and `seaborn`. You can use scatter plots, pair plots, histogram plots, heatmaps, distribution plots, boxplots or other relevant plots to explore the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32ee8a0806703c8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'manufacturing.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2129478494.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mDATASET_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"manufacturing.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmanufacturing_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m print(\n\u001b[1;32m      5\u001b[0m     \u001b[0;34mf\"Loaded manufacturing dataset with {manufacturing_df.shape[0]:,} rows and {manufacturing_df.shape[1]} columns.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'manufacturing.csv'"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = Path(\"manufacturing.csv\")\n",
    "\n",
    "manufacturing_df = pd.read_csv(DATASET_PATH)\n",
    "print(\n",
    "    f\"Loaded manufacturing dataset with {manufacturing_df.shape[0]:,} rows and {manufacturing_df.shape[1]} columns.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde3ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_overview = pd.DataFrame(\n",
    "    {\n",
    "        \"dtype\": manufacturing_df.dtypes,\n",
    "        \"missing_values\": manufacturing_df.isna().sum(),\n",
    "    }\n",
    ")\n",
    "\n",
    "column_overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5afc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "manufacturing_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07558275",
   "metadata": {},
   "outputs": [],
   "source": [
    "manufacturing_df.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d434e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    manufacturing_df.corr(numeric_only=True),\n",
    "    annot=True,\n",
    "    cmap=\"Blues\",\n",
    "    fmt=\".2f\",\n",
    ")\n",
    "plt.title(\"Correlation Heatmap for Manufacturing Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3cb5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "manufacturing_df.hist(figsize=(12, 8), bins=20)\n",
    "plt.suptitle(\"Distribution of Manufacturing Features\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18402236",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"Quality Rating\"\n",
    "feature_columns = [\n",
    "    \"Temperature (°C)\",\n",
    "    \"Pressure (kPa)\",\n",
    "    \"Temperature x Pressure\",\n",
    "    \"Material Fusion Metric\",\n",
    "    \"Material Transformation Metric\",\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(len(feature_columns), 1, figsize=(6, 18), sharey=True)\n",
    "\n",
    "for ax, feature in zip(axes, feature_columns):\n",
    "    sns.scatterplot(\n",
    "        data=manufacturing_df,\n",
    "        x=feature,\n",
    "        y=target_column,\n",
    "        ax=ax,\n",
    "        alpha=0.6,\n",
    "    )\n",
    "    ax.set_title(f\"{feature} vs. {target_column}\")\n",
    "\n",
    "fig.suptitle(\"Feature Relationships with Quality Rating\", y=0.92)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a84a06ff7bb9ccf",
   "metadata": {},
   "source": [
    "### 2. Prepare the dataset\n",
    "\n",
    "1. **Choose a feature**: Choose one column from the dataset to use as an independent feature for the regression model. Explain your choice based on the findings from the previous step.\n",
    "\n",
    "2. **Split the Data**: Use `train_test_split()` from `sklearn.model_selection` to divide the data into training and testing sets. This allows us to assess the model's ability to generalize to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "671c24b176ec1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add your code; add more cells as needed; add explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c74faea779cb3",
   "metadata": {},
   "source": [
    "### 3. Fitting Polynomial Regression Models\n",
    "\n",
    "1. **Polynomial features**: Transform your independent feature to include polynomial terms. Use `PolynomialFeatures` from `sklearn.preprocessing` to generate polynomial terms up to the chosen degree. \n",
    "2. **Find the best**: Find the best polynomial degree for the independent feature. Test with a low-degree polynomial (e.g., degree 2) and increase the degree to see how the fit changes  (This is best done by a loop. There is usually a sweet spot, where the MSE is optimally low). Evaluate the fit my measuring the Mean Squared Error. Use `mean_squared_error` from `sklearn.metrics`. You can also experiment with other metrics like `r2_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88d3887970b2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add your code; add more cells as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e233962847f9970",
   "metadata": {},
   "source": [
    "### 4. Comparison\n",
    "1. **Fit Linear Regression Model**: First, fit a simple linear regression model on the same data as a baseline.\n",
    "\n",
    "2. **Overlay Polynomial and Linear Predictions**: On a scatter plot of the data, plot the predictions from both the polynomial and linear models to compare.\n",
    "\n",
    "3. **Observe Differences**: The polynomial model should capture non-linear patterns in the data that the linear model cannot, especially as the polynomial degree increases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a0de491c4c406fed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T13:29:54.756900Z",
     "start_time": "2024-11-13T13:29:54.754217Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: add your code; add more cells as needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
